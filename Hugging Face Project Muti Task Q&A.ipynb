{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Question Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\krsin\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Validation Loss: 1.0792, Validation Accuracy: 0.9000\n",
      "Epoch 2 - Validation Loss: 1.0565, Validation Accuracy: 0.9000\n",
      "Epoch 3 - Validation Loss: 1.0328, Validation Accuracy: 0.7000\n",
      "Predicted category: Employee Role\n"
     ]
    }
   ],
   "source": [
    "#importing Necessary Libraries\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define the training and validation datasets\n",
    "train_texts = [\n",
    "    \"What department handles sales?\",\n",
    "    \"What is the role of an employee in HR?\",\n",
    "    \"Any news about the company?\",\n",
    "    \"What are the requirements for a software engineer position?\",\n",
    "    \"How does the marketing department contribute to the company's growth?\",\n",
    "    \"Any updates on the company's recent product launch?\",\n",
    "    \"What are the benefits provided to employees?\",\n",
    "    \"How can I apply for a job in the finance department?\",\n",
    "    \"Are there any recent changes in the company's leadership?\",\n",
    "    \"What is the typical work schedule for a customer support representative?\"\n",
    "]\n",
    "train_labels = [0, 1, 2, 1, 0, 2, 1, 0, 2, 1]  # Corresponding labels for each training example\n",
    "\n",
    "val_texts = [\n",
    "    \"How can I contact the IT department?\",\n",
    "    \"What are the responsibilities of a manager?\",\n",
    "    \"Any updates on the company's financial performance?\",\n",
    "    \"What qualifications are required for a sales representative position?\",\n",
    "    \"How does the human resources department handle employee benefits?\",\n",
    "    \"Are there any recent press releases from the company?\",\n",
    "    \"What is the process for requesting time off?\",\n",
    "    \"How can I reach the customer service department?\",\n",
    "    \"Any updates on the company's expansion plans?\",\n",
    "    \"What is the average salary for a software developer?\"\n",
    "]\n",
    "val_labels = [0, 1, 2, 1, 0, 2, 1, 0, 2, 1]  # Corresponding labels for each validation example\n",
    "\n",
    "# Tokenize the texts and create input tensors\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(train_encodings[\"input_ids\"]),\n",
    "    torch.tensor(train_encodings[\"attention_mask\"]),\n",
    "    torch.tensor(train_labels)\n",
    ")\n",
    "val_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(val_encodings[\"input_ids\"]),\n",
    "    torch.tensor(val_encodings[\"attention_mask\"]),\n",
    "    torch.tensor(val_labels)\n",
    ")\n",
    "\n",
    "# Training hyperparameters\n",
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "num_epochs = 3\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predicted_labels = logits.argmax(dim=1)\n",
    "            correct_predictions += (predicted_labels == labels).sum().item()\n",
    "            total_predictions += len(labels)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    val_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} - Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "model.save_pretrained(\"./question_classification_model\")\n",
    "tokenizer.save_pretrained(\"./question_classification_model\")\n",
    "\n",
    "# Example usage after training\n",
    "def classify_question(question):\n",
    "    # Load the fine-tuned model and tokenizer\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"./question_classification_model\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"./question_classification_model\")\n",
    "\n",
    "    # Tokenize the question\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        question,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Classify the question\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = logits.argmax().item()\n",
    "\n",
    "    # Define the categories\n",
    "    categories = [\"Company Department\", \"Employee Role\", \"Company News\"]\n",
    "\n",
    "    # Return the predicted category\n",
    "    return categories[predicted_class]\n",
    "\n",
    "# Example usage\n",
    "question = \"What department handles sales?\"\n",
    "predicted_category = classify_question(question)\n",
    "print(f\"Predicted category: {predicted_category}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Information Retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Create the SQLite database\n",
    "conn = sqlite3.connect(\"employee_database.db\")\n",
    "db_cursor = conn.cursor()\n",
    "\n",
    "# Drop the employees table if it already exists\n",
    "db_cursor.execute(\"DROP TABLE IF EXISTS employees\")\n",
    "\n",
    "# Create the employees table\n",
    "db_cursor.execute(\"\"\"\n",
    "    CREATE TABLE employees (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        name TEXT,\n",
    "        role TEXT,\n",
    "        department TEXT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Insert sample employee data\n",
    "employees_data = [\n",
    "    (1, \"John Doe\", \"sales representative\", \"Sales\"),\n",
    "    (2, \"Jane Smith\", \"customer support representative\", \"Customer Support\"),\n",
    "    (3, \"Michael Johnson\", \"software engineer\", \"Engineering\"),\n",
    "    (4, \"Emily Davis\", \"marketing specialist\", \"Marketing\"),\n",
    "    (5, \"Robert Brown\", \"HR manager\", \"HR\")\n",
    "]\n",
    "\n",
    "db_cursor.executemany(\"INSERT INTO employees VALUES (?, ?, ?, ?)\", employees_data)\n",
    "\n",
    "# Commit the changes and close the database connection\n",
    "conn.commit()\n",
    "db_cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Define the employee details\n",
    "employee_details = [\n",
    "    {\"id\": 1, \"name\": \"John Doe\", \"role\": \"sales representative\", \"department\": \"Sales\"},\n",
    "    {\"id\": 2, \"name\": \"Jane Smith\", \"role\": \"customer support representative\", \"department\": \"Customer Support\"},\n",
    "    {\"id\": 3, \"name\": \"Michael Johnson\", \"role\": \"software engineer\", \"department\": \"Engineering\"},\n",
    "    {\"id\": 4, \"name\": \"Emily Davis\", \"role\": \"marketing specialist\", \"department\": \"Marketing\"},\n",
    "    {\"id\": 5, \"name\": \"Robert Brown\", \"role\": \"HR manager\", \"department\": \"HR\"}\n",
    "]\n",
    "\n",
    "# Define the field names for the CSV file\n",
    "field_names = [\"id\", \"name\", \"role\", \"department\"]\n",
    "\n",
    "# Write the employee details to the CSV file\n",
    "with open(\"employee_details.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(employee_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Details:\n",
      "1 John Doe sales representative\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "import sqlite3\n",
    "\n",
    "# Function to retrieve employee details from an SQL database\n",
    "def retrieve_employee_details(employee_role):\n",
    "    # Connect to the SQL database\n",
    "    conn = sqlite3.connect(\"employee_database.db\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Execute the SQL query to retrieve employee details\n",
    "    cursor.execute(\"SELECT * FROM employees WHERE role=?\", (employee_role,))\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Close the database connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    # Return the retrieved employee details\n",
    "    return rows\n",
    "\n",
    "# Function to retrieve company news from a news API\n",
    "def retrieve_company_news():\n",
    "    # Make a request to the news API\n",
    "    response = requests.get(\"https://api.example.com/news\")\n",
    "\n",
    "    # Parse the response and retrieve the company news\n",
    "    news_data = response.json()\n",
    "    company_news = news_data[\"company_news\"]\n",
    "\n",
    "    # Return the retrieved company news\n",
    "    return company_news\n",
    "\n",
    "# Function to retrieve department details from a CSV file\n",
    "def retrieve_department_details(department):\n",
    "    # Read the CSV file\n",
    "    with open(\"department_details.csv\", \"r\") as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        rows = [row for row in reader if row[\"department\"] == department]\n",
    "\n",
    "    # Return the retrieved department details\n",
    "    return rows\n",
    "\n",
    "# Example usage\n",
    "question = \"What department handles sales?\"\n",
    "\n",
    "# Classify the question using the question classification model\n",
    "predicted_category = classify_question(question)\n",
    "\n",
    "# Retrieve relevant information based on the predicted category\n",
    "if predicted_category == \"Company Department\":\n",
    "    department_details = retrieve_department_details(\"sales\")\n",
    "    print(\"Department Details:\")\n",
    "    for row in department_details:\n",
    "        print(row[\"name\"], row[\"description\"])\n",
    "elif predicted_category == \"Employee Role\":\n",
    "    employee_role = \"sales representative\"\n",
    "    employee_details = retrieve_employee_details(employee_role)\n",
    "    print(\"Employee Details:\")\n",
    "    for row in employee_details:\n",
    "        print(row[0], row[1], row[2])\n",
    "elif predicted_category == \"Company News\":\n",
    "    company_news = retrieve_company_news()\n",
    "    print(\"Company News:\")\n",
    "    for news in company_news:\n",
    "        print(news[\"title\"], news[\"description\"])\n",
    "else:\n",
    "    print(\"Invalid category\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Answer Generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential Answer: sales operations of the company\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "# User's question\n",
    "question = \"What is the sales department responsible for?\"\n",
    "\n",
    "# Retrieved information as context\n",
    "context = \"The sales department is responsible for handling the sales operations of the company. They manage client relationships, negotiate deals, and meet sales targets.\"\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
    "\n",
    "# Generate potential answer\n",
    "answer_start_scores, answer_end_scores = model(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"]).values()\n",
    "answer_start = torch.argmax(answer_start_scores)\n",
    "answer_end = torch.argmax(answer_end_scores) + 1\n",
    "\n",
    "# Decode and print the potential answer\n",
    "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
    "print(\"Potential Answer:\", answer)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer is present in the context.\n",
      "Answer contains keywords related to the question.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import re\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "# User's question\n",
    "question = \"What is the sales department responsible for?\"\n",
    "\n",
    "# Retrieved information as context\n",
    "context = \"The sales department is responsible for handling the sales operations of the company. They manage client relationships, negotiate deals, and meet sales targets.\"\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
    "\n",
    "# Generate potential answer\n",
    "answer_start_scores, answer_end_scores = model(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"]).values()\n",
    "answer_start = torch.argmax(answer_start_scores)\n",
    "answer_end = torch.argmax(answer_end_scores) + 1\n",
    "\n",
    "# Decode the potential answer\n",
    "potential_answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
    "\n",
    "# Validate the answer\n",
    "# Check if the potential answer is present in the context\n",
    "if potential_answer.lower() in context.lower():\n",
    "    print(\"Answer is present in the context.\")\n",
    "else:\n",
    "    print(\"Answer is not present in the context.\")\n",
    "\n",
    "# Check if the potential answer contains keywords related to the question\n",
    "keywords = re.findall(r'\\b\\w+\\b', question.lower())\n",
    "if any(keyword.lower() in potential_answer.lower() for keyword in keywords):\n",
    "    print(\"Answer contains keywords related to the question.\")\n",
    "else:\n",
    "    print(\"Answer does not contain keywords related to the question.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#API Structure: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [20/May/2023 20:03:18] \"GET /api/answer HTTP/1.1\" 405 -\n",
      "127.0.0.1 - - [20/May/2023 20:03:18] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/May/2023 20:03:47] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [20/May/2023 20:03:47] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import re\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "@app.route('/api/answer', methods=['POST'])\n",
    "def get_answer():\n",
    "    # Get the question from the request\n",
    "    question = request.json['question']\n",
    "\n",
    "    # Get the context from the request\n",
    "    context = request.json['context']\n",
    "\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer.encode_plus(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate potential answer\n",
    "    answer_start_scores, answer_end_scores = model(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"]).values()\n",
    "    answer_start = torch.argmax(answer_start_scores)\n",
    "    answer_end = torch.argmax(answer_end_scores) + 1\n",
    "\n",
    "    # Decode the potential answer\n",
    "    potential_answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))\n",
    "\n",
    "    # Validate the answer\n",
    "    # Check if the potential answer is present in the context\n",
    "    answer_present = potential_answer.lower() in context.lower()\n",
    "\n",
    "    # Check if the potential answer contains keywords related to the question\n",
    "    keywords = re.findall(r'\\b\\w+\\b', question.lower())\n",
    "    answer_contains_keywords = any(keyword.lower() in potential_answer.lower() for keyword in keywords)\n",
    "\n",
    "    # Prepare the response\n",
    "    response = {\n",
    "        'question': question,\n",
    "        'context': context,\n",
    "        'answer': potential_answer,\n",
    "        'answer_present': answer_present,\n",
    "        'answer_contains_keywords': answer_contains_keywords\n",
    "    }\n",
    "\n",
    "    return jsonify(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://localhost:5000/api/answer'\n",
    "payload = {\n",
    "    'question': 'What is the sales department responsible for?',\n",
    "    'context': 'The sales department is responsible for handling the sales operations of the company. They manage client relationships, negotiate deals, and meet sales targets.'\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
